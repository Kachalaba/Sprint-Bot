# Step Report — Technical Audit

## Что сделано
- Построена карта репозитория и задокументирована в `REPORT_AUDIT.md` (ключевые директории и сервисы).【F:REPORT_AUDIT.md†L3-L34】
- Собран снимок зависимостей (`requirements.txt`, `pip freeze`), зафиксирован стек инструментов CI/CD.【F:REPORT_AUDIT.md†L36-L68】
- Проведён ручной аудит кода: выявлены узкие места Google Sheets, блокирующие вызовы и артефакты конфликтов.【F:REPORT_AUDIT.md†L70-L126】
- Сформирована матрица рисков/рекомендаций, подготовлен roadmap на ближайшие спринты.【F:REPORT_AUDIT.md†L128-L168】

## План / почему так
1. **Инвентаризация** — без карты и зависимостей невозможно приоритизировать технический долг.
2. **Фокус на I/O и интеграциях** — бот упирается в Google Sheets, поэтому анализировали все обращения к ним (handlers/services).
3. **Документация** — оформили результаты в `REPORT_AUDIT.md`, чтобы команда могла ссылаться на выводы.

## Риски
- Высокий риск деградации бота из-за блокирующих вызовов Google Sheets в хэндлерах.【F:handlers/progress.py†L398-L414】【F:handlers/sprint_actions.py†L111-L128】
- Существующие конфликты/артефакты (`handlers/sprint_actions.py.save`) могут случайно попасть в продуктив и сломать импорт модулей.【F:handlers/sprint_actions.py.save†L1-L38】
- Недостаточная типизация и отсутствие pre-commit повышают вероятность регрессий при будущих изменениях.【F:mypy.ini†L1-L8】【F:pyproject.toml†L1-L8】

## Что дальше
- Приоритезировать вынос горячих путей на SQLite и внедрение async-обёрток для Google Sheets (Quick wins в `REPORT_AUDIT.md`).【F:REPORT_AUDIT.md†L142-L158】
- Навести порядок в репозитории: удалить `.save` файлы, добавить проверки на артефакты, усилить линтинг.【F:REPORT_AUDIT.md†L90-L126】
- Запланировать выполнение roadmap (2–4 спринта) с акцентом на миграцию данных и хардненинг инфраструктуры.【F:REPORT_AUDIT.md†L160-L168】

---

# Step Report — Architecture Skeleton

## Карта репозитория
- `bot.py` / `handlers/` — точка входа aiogram и набор хэндлеров команд, включая онбординг, отчёты, экспорт.
- `services/` — процедурные сервисы, обращающиеся к Google Sheets и аналитике команд.
- `utils/`, `filters/`, `middlewares/` — вспомогательные утилиты, кастомные фильтры и промежуточные слои aiogram.
- `db/` — миграции и вспомогательные скрипты работы с БД.
- `reports/`, `notifications.py`, `template_service.py` — генерация отчётов и уведомлений.
- `tests/` — минимальный набор тестов для существующего функционала.
- `sprint_bot/` — новый модуль с каркасом Domain/Application/Infrastructure.

## План работ
1. Зафиксировать архитектурные требования и карту репозитория (данный отчёт).
2. Спроектировать DTO и интерфейсы портов для доменного слоя.
3. Сформировать `ARCH_PLAN.md` с поэтапной миграцией и рисками.
4. Обновить документацию (`CHANGELOG.md`, `REPORT.md`) и подготовить основу для последующих PR.

## Что сделано
- Добавлен пакет `sprint_bot` с сущностями домена и портами приложения для атлетов, тренеров, гонок и телеметрии.
- Описаны сервисные порты для Telegram, Sheets/Postgres, S3 и Sentry, заложены инфраструктурные пространства имён.
- Подготовлен документ `ARCH_PLAN.md` с целевой архитектурой и планом миграции без даунтайма.

## Риски
- Требуется аккуратная реализация адаптеров к Google Sheets, иначе возможна деградация при двойной записи.
- Новые интерфейсы пока не покрыты тестами, что откладывает контроль совместимости.

## Что дальше
- Реализовать адаптеры `WorksheetService` и `AthleteRepository` поверх существующих сервисов.
- Спроектировать первые use-cases (например, импорт результатов гонок).
- Подготовить интеграцию с Sentry и объектным хранилищем в новых пакетах.

# Step Report — Storage Migration Planning

## Карта репозитория
```
Sprint-Bot/
├── bot.py — текущая точка входа бота на aiogram 2.x с процедурной логикой.
├── sprint_bot/ — новый модуль с DDD-скелетом (domain/application/infrastructure).
│   ├── application/ — порты и use-case'ы следующего поколения.
│   ├── domain/ — чистые модели атлетов, гонок, рекордов, SoB.
│   └── infrastructure/ — адаптеры Telegram, storage, observability.
├── handlers/, keyboards/, filters/, middlewares/ — legacy aiogram-хэндлеры и обвязка.
├── services/, utils/, notifications.py, template_service.py — процедурные сервисы с обращениями к Google Sheets.
├── db/ — SQL-миграции и скрипты для исторической БД.
├── data/, reports/, examples/ — артефакты отчётности и дампы сплитов.
├── docker-compose.yml, Dockerfile, entrypoint.sh — контейнеризация и запуск.
├── tests/ — регрессионные тесты бота.
└── docs: README.md, ARCH_PLAN.md, REPORT*.md, CHANGELOG.md — документация и планы.
```

## План работ
1. Спроектировать слой `Storage` с конфигурируемым backend (`sheets`/`postgres`) и выделить контракты `AthletesRepo`, `CoachesRepo`, `ResultsRepo`, `RecordsRepo` в `application`.
2. Реализовать адаптер Google Sheets на новом слое, постепенно оборачивая существующие сервисы.
3. Подготовить модуль `infra/db` с SQLAlchemy 2.0 моделями, Alembic-конфигурацией и make-таргетом `make migrate`.
4. Реализовать `PostgresStorage` и репозитории, покрыв основную доменную модель (атлеты, тренеры, результаты, рекорды).
5. Написать idempotent-скрипт импорта данных из Sheets → Postgres (`make import_sheets`) с логом пропусков.
6. Обновить docker-compose: запуск Postgres, прогон миграций при старте, конфиг через `.env`/`.env.example`.
7. Прогнать тесты/линт, обновить документацию и инструкции по деплою.

## Риски
- **Сложность схемы**: несовпадение доменных сущностей с текущими таблицами в Sheets может привести к сложной миграции.
- **Двойная запись**: при параллельной работе двух стораджей возможно расхождение данных; нужно обеспечить единый источник правды.
- **Производительность миграции**: импорт сплитов большого объёма может превысить лимиты Google API; потребуется батчевание и ретраи.
- **Совместимость legacy-кода**: существующие сервисы тесно связаны со структурами листов; рефакторинг может породить регрессии.

## Что дальше
- Провести ревизию сервисов, чтобы определить минимальный срез данных для первой версии Postgres.
- Подготовить каркас конфигурации (`settings.py`, `.env.example`) для переключения backend.
- Спроектировать схему таблиц и Alembic-миграции под целевые доменные объекты.

## Диффы
- `git diff --stat`: `CHANGELOG.md |  1 +`, `REPORT.md | 39 +`.

## Команды
- `git status -sb`
- `git diff --stat`

# Step Report — Alembic Migration Setup

## Что сделано
- Добавлены конфигурация `alembic.ini`, скрипт `env.py` и шаблон `script.py.mako`.
- Сгенерирована стартовая миграция `20240507_0001_create_core_tables` с таблицами атлетов, тренеров, гонок, сплитов и рекордов.

## Почему так
- Alembic обеспечивает версионирование схемы и согласуется с SQLAlchemy моделями из `infra/db`.
- Первая миграция отражает доменную модель, упрощая дальнейшее расширение.

## Риски
- Разделение default-значений между SQLAlchemy и БД требует синхронизации (особенно `updated_at`).
- При запуске без `DB_URL` Alembic упадёт; нужна корректная настройка окружения.

## Что дальше
- Подготовить make-команды `migrate` и `import_sheets`.
- Обновить docker-compose для запуска Postgres по умолчанию.

## Диффы
- `git diff --stat`: `alembic.ini`, `alembic/env.py`, `alembic/script.py.mako`, `alembic/versions/20240507_0001_create_core_tables.py` (новые файлы).

## Команды
- `git status -sb`
# Step Report — Postgres Storage Foundations

## Что сделано
- Добавлен пакет `infra/db` с SQLAlchemy 2.0 моделями, сессиями и репозиториями для Postgres.
- Реализован `PostgresStorage` на асинхронном движке, подключенный к фабрике `create_storage`.
- В `requirements.txt` добавлены зависимости `SQLAlchemy`, `asyncpg`, `alembic`.

## Почему так
- SQLAlchemy 2.0 + `asyncpg` обеспечивает асинхронный доступ и совместимость с Alembic.
- Слои репозиториев повторяют доменные контракты, что упрощает миграцию use-case'ов.

## Риски
- При загрузке больших гонок возможны дополнительные запросы из-за выборки сплитов; потребуется профилирование.
- Upsert-логика через `merge`/`add` может конфликтовать с одновременными миграциями — нужно следить за блокировками.

## Что дальше
- Настроить Alembic и начальную миграцию схемы.
- Подготовить docker-compose с Postgres и make-команды для миграций/импорта.

## Диффы
- `git diff --stat`: `requirements.txt | 3 +`, `sprint_bot/infrastructure/storage/postgres.py | 69 +/-`, `infra/db/*` (новые файлы).

## Команды
- `git status -sb`
- `git diff --stat`
# Step Report — Storage Layer Interfaces

## Что сделано
- Определены новые контракты `AthletesRepo`, `CoachesRepo`, `ResultsRepo`, `RecordsRepo` в приложении и вынесен фасад `Storage`.
- Обновлён экспорт портов для использования единых абстракций стораджа в адаптерах.

## Почему так
- Единая точка монтирования репозиториев упростит переключение между Google Sheets и Postgres реализациями.
- Переименование согласовано с roadmap и будущими use-case'ами (Results/Records vs Race/Performance).

## Риски
- Legacy-код пока не использует новые контракты, потребуется адаптация сервисов при интеграции.
- Возможны расхождения с существующими DTO, если структура доменных сущностей изменится в процессе миграции.

## Что дальше
- Реализовать адаптер `GoogleSheetsStorage`, возвращающий репозитории поверх текущих сервисов.
- Подготовить конфигурацию переключения backend через `.env` и фабрику стораджа.

## Диффы
- `git diff --stat`: `CHANGELOG.md |  1 +`, `REPORT.md | 24 +`, `sprint_bot/application/ports/__init__.py | 17 +/-`, `sprint_bot/application/ports/repositories.py |  8 +/-`.

## Команды
- `git status -sb`

# Step Report — Tooling & Import Pipeline

## Что сделано
- Добавлен `Makefile` с командами `make migrate` и `make import_sheets`.
- Реализован скрипт `scripts/import_sheets.py` для батч-миграции Sheets → Postgres (идемпотентно, с логами).
- Обновлён `docker-compose.yml`: добавлен сервис Postgres, переменные `DB_URL`/`STORAGE_BACKEND`.
- README пополнен инструкциями з міграцій.

## Почему так
- Makefile спрощує стандартні операції розробника та CI.
- Скрипт використовує нові стораджі й централізований логгер із ротацією.
- Docker Compose забезпечує холодний старт інфраструктури (Postgres + бот).

## Риски
- Імпорт поки тягне тільки активних атлетів/тренерів; для історичних архівів потрібне розширення API Sheets.
- Ручний запуск скрипта без валідних облікових даних призведе до винятків — потрібно фіксувати в документації.

## Что дальше
- Покрити `scripts/import_sheets` тестами на моках Google Sheets.
- Інтегрувати PostgresStorage у актуальні use-case'и бота.

## Диффы
- `git diff --stat`: `Makefile`, `scripts/import_sheets.py`, `docker-compose.yml`, `README.md`.

## Команды
- `git status -sb`
# Step Report — Google Sheets Storage Backend

## Что сделано
- Реализован `GoogleSheetsStorage` с репозиториями для атлетов, тренеров, результатов и рекордов.
- Добавлен конфиг стораджа (`StorageSettings`, `StorageBackend`) и фабрика `create_storage`.
- Обновлён `.env.example` с переменными `STORAGE_BACKEND`, `DB_URL`, `GOOGLE_APPLICATION_CREDENTIALS`.

## Почему так
- Асинхронные обёртки (`asyncio.to_thread`) позволяют использовать существующие листы без блокировки event loop.
- Упрощённые парсеры (дат, таймингов, булевых полей) покрывают большинство форматов, встреченных в таблицах.

## Риски
- Структура листов может отличаться от ожидаемой схемы; строки без обязательных полей пропускаются.
- Репозиторий работает только на чтение — для записи в Sheets нужна отдельная реализация.

## Что дальше
- Реализовать `PostgresStorage` и SQLAlchemy модели.
- Подготовить миграцию Alembic и docker-compose c Postgres.

## Диффы
- `git diff --stat`: `.env.example | 3 +`, `sprint_bot/infrastructure/storage/__init__.py | 35 +`, `config.py`, `google_sheets.py`, `postgres.py` (новые файлы).

## Команды
- `git status -sb`
- `git diff --stat`